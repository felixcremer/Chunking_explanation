{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05d898d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "448b3316",
   "metadata": {},
   "source": [
    "In this notebook you will learn how the chunking of the data set affects the reading and processing speed depending on the chunking and on the access patterns you need for your analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8895f4b4",
   "metadata": {},
   "source": [
    "# Understand chunking and rechunking\n",
    "\n",
    "Task: Use your favorite NetCDF package and method to compute \n",
    "\n",
    "a) mean and \n",
    "b) median per spatial pixel\n",
    "\n",
    "for the air_temperature_2m variable in this dataset without loading the whole data into memory (7GB uncompressed data per variable)\n",
    "\n",
    "We first test access time along different axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "266ff5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disk Array with size 1440 x 720 x 1794\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using NetCDF\n",
    "using DiskArrays: eachchunk\n",
    "\n",
    "v = NetCDF.open(\"esdc_subset2_compressed.nc\",\"layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60808676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.003255 seconds (40 allocations: 3.956 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time v[:,:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf3c0573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28.262194 seconds (38 allocations: 8.672 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time v[1,1,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fba1cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.529157 seconds (40 allocations: 3.956 MiB)\n"
     ]
    }
   ],
   "source": [
    "vchunked = NetCDF.open(\"esdc_subset_compressed.nc\",\"layer\")\n",
    "\n",
    "@time vchunked[:,:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdb76581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.240300 seconds (38 allocations: 8.672 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time vchunked[1,1,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b1a7d",
   "metadata": {},
   "source": [
    "Access along spatial strides is much faster than access of time series\n",
    "because of the internal storage in the netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6311fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1×1794 DiskArrays.GridChunks{3}:\n",
       "[:, :, 1] =\n",
       " (1:1440, 1:720, 1:1)\n",
       "\n",
       "[:, :, 2] =\n",
       " (1:1440, 1:720, 2:2)\n",
       "\n",
       "[:, :, 3] =\n",
       " (1:1440, 1:720, 3:3)\n",
       "\n",
       ";;; … \n",
       "\n",
       "[:, :, 1792] =\n",
       " (1:1440, 1:720, 1792:1792)\n",
       "\n",
       "[:, :, 1793] =\n",
       " (1:1440, 1:720, 1793:1793)\n",
       "\n",
       "[:, :, 1794] =\n",
       " (1:1440, 1:720, 1794:1794)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eachchunk(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93a3f1",
   "metadata": {},
   "source": [
    "\n",
    "DiskArrays.jl knows about the internal chunking structure and provides special implementations\n",
    "for mapreduce which is used in the implementation of mean for AbstractArray\n",
    "The following two aggregations access every chunk only once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36dc2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31.101223 seconds (4.04 M allocations: 7.130 GiB, 3.05% gc time, 2.98% compilation time)\n",
      " 30.049550 seconds (707.62 k allocations: 6.962 GiB, 0.76% gc time, 0.56% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×1×1794 Array{Float32, 3}:\n",
       "[:, :, 1] =\n",
       " NaN\n",
       "\n",
       "[:, :, 2] =\n",
       " NaN\n",
       "\n",
       "[:, :, 3] =\n",
       " NaN\n",
       "\n",
       ";;; … \n",
       "\n",
       "[:, :, 1792] =\n",
       " 277.7125\n",
       "\n",
       "[:, :, 1793] =\n",
       " 277.91547\n",
       "\n",
       "[:, :, 1794] =\n",
       " 277.78473"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using Statistics\n",
    "@time mean(v,dims=3)\n",
    "\n",
    "@time mean(v,dims=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efaad6",
   "metadata": {},
   "source": [
    "\n",
    "This gets more difficult for the median, because here we need the full ts in memory.\n",
    "This makes it impossible to compute the median in a single pass\n",
    "Let's try this on a small subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1572555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.814163 seconds (2.51 M allocations: 139.902 MiB, 0.05% gc time, 0.56% compilation time)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "v2 = view(v,1:2, 1:2,:)\n",
    "out = zeros(size(v2,1),size(v2,2))\n",
    "\n",
    "@time for ilat in axes(v2,2), ilon in axes(v2,1)\n",
    "    out[ilon,ilat] = median(v2[ilon,ilat,:])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3334d55",
   "metadata": {},
   "source": [
    "\n",
    "This already takes ages to finish for 4 grid cells only. It would be better to e.g. always read approx 1GB of data at a time and consecutively do the computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1110fab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{UnitRange{Int64}}:\n",
       " 1:90\n",
       " 91:180\n",
       " 181:270\n",
       " 271:360\n",
       " 361:450\n",
       " 451:540\n",
       " 541:630\n",
       " 631:720"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using ProgressMeter\n",
    "out = zeros(size(v,1),size(v,2))\n",
    "latsteps = 90\n",
    "latranges = [(i*90-latsteps+1):(i*90) for i in 1:(720 ÷ latsteps)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41d2dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@showprogress for ilat in latranges\n",
    "    out[:,ilat] = median(v[:,ilat,:],dims=3)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf31ab",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This finishes in a reasonable amount of time. \n",
    "Alternatively we can use YAXArrays.jl which does exactly this workflow for a given cache size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccaba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/fcremer/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fdc0c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YAXArray with the following dimensions\n",
       "lon                 Axis with 1440 Elements from -179.875 to 179.875\n",
       "lat                 Axis with 720 Elements from 89.875 to -89.875\n",
       "time                Axis with 1748 Elements from 1980-01-05T00:00:00 to 2017-12-31T00:00:00\n",
       "name: layer\n",
       "units: W m-2\n",
       "Total size: 6.75 GB\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using YAXArrays\n",
    "ds = open_dataset(\"esdc_subset_compressed.nc\")\n",
    "\n",
    "ds.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "714adf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:16\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YAXArray with the following dimensions\n",
       "lon                 Axis with 1440 Elements from -179.875 to 179.875\n",
       "lat                 Axis with 720 Elements from 89.875 to -89.875\n",
       "Total size: 3.96 MB\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medtair = mapslices(median, ds.layer, dims=\"Time\", max_cache=1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f33fc8",
   "metadata": {},
   "source": [
    "\n",
    "YAXArrays will also take care of parallelization, for IO-limited processing tasks, we use Distributed.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21d468a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, Zarr\n",
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e062fa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n",
      "      From worker 6:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n",
      "      From worker 7:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n",
      "      From worker 9:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n",
      "      From worker 8:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/NFDI4Earth/juliaeoTerceira2023/handson_datacubes`\n"
     ]
    }
   ],
   "source": [
    "@everywhere begin \n",
    "    using Pkg\n",
    "    Pkg.activate(\".\")\n",
    "    Pkg.instantiate()\n",
    "    #Pkg.status()\n",
    "    using YAXArrays, Statistics, NetCDF, Zarr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8335db39",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ProcessExitedException(5)",
     "output_type": "error",
     "traceback": [
      "ProcessExitedException(5)",
      "",
      "Stacktrace:",
      "  [1] worker_from_id(pg::Distributed.ProcessGroup, i::Int64)",
      "    @ Distributed ~/.julia/juliaup/julia-1.8.4+0.x64.linux.gnu/share/julia/stdlib/v1.8/Distributed/src/cluster.jl:1093",
      "  [2] worker_from_id",
      "    @ ~/.julia/juliaup/julia-1.8.4+0.x64.linux.gnu/share/julia/stdlib/v1.8/Distributed/src/cluster.jl:1090 [inlined]",
      "  [3] remotecall(::Function, ::Int64; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Distributed ~/.julia/juliaup/julia-1.8.4+0.x64.linux.gnu/share/julia/stdlib/v1.8/Distributed/src/remotecall.jl:447",
      "  [4] remotecall",
      "    @ ~/.julia/juliaup/julia-1.8.4+0.x64.linux.gnu/share/julia/stdlib/v1.8/Distributed/src/remotecall.jl:447 [inlined]",
      "  [5] #95",
      "    @ ./none:0 [inlined]",
      "  [6] iterate",
      "    @ ./generator.jl:47 [inlined]",
      "  [7] _all(f::Base.var\"#343#345\", itr::Base.Generator{Vector{Int64}, YAXArrays.DAT.var\"#95#97\"{YAXArrays.DAT.var\"#106#110\"{Future}}}, #unused#::Colon)",
      "    @ Base ./reduce.jl:1250",
      "  [8] all",
      "    @ ./reduce.jl:1246 [inlined]",
      "  [9] Dict(kv::Base.Generator{Vector{Int64}, YAXArrays.DAT.var\"#95#97\"{YAXArrays.DAT.var\"#106#110\"{Future}}})",
      "    @ Base ./dict.jl:131",
      " [10] pmap_with_data(f::Function, p::WorkerPool, c::DiskArrays.GridChunks{2}; initfunc::Function, progress::Progress, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ YAXArrays.DAT ~/.julia/packages/YAXArrays/Fe7F8/src/DAT/DAT.jl:660",
      " [11] pmap_with_data(f::Function, c::DiskArrays.GridChunks{2}; initfunc::Function, kwargs::Base.Pairs{Symbol, Progress, Tuple{Symbol}, NamedTuple{(:progress,), Tuple{Progress}}})",
      "    @ YAXArrays.DAT ~/.julia/packages/YAXArrays/Fe7F8/src/DAT/DAT.jl:673",
      " [12] runLoop(dc::YAXArrays.DAT.DATConfig{1, 1}, showprog::Bool)",
      "    @ YAXArrays.DAT ~/.julia/packages/YAXArrays/Fe7F8/src/DAT/DAT.jl:698",
      " [13] mapCube(::typeof(median), ::Tuple{YAXArray{Union{Missing, Float32}, 3, DiskArrayTools.CFDiskArray{Float32, 3, Float32, DiskArrays.SubDiskArray{Float32, 3}}, Vector{RangeAxis}}}; max_cache::Float64, indims::InDims, outdims::OutDims, inplace::Bool, ispar::Bool, debug::Bool, include_loopvars::Bool, showprog::Bool, irregular_loopranges::Bool, nthreads::Dict{Int64, Int64}, loopchunksize::Dict{Any, Any}, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ YAXArrays.DAT ~/.julia/packages/YAXArrays/Fe7F8/src/DAT/DAT.jl:475",
      " [14] #mapCube#36",
      "    @ ~/.julia/packages/YAXArrays/Fe7F8/src/DAT/DAT.jl:303 [inlined]",
      " [15] #mapslices#50",
      "    @ ~/.julia/packages/YAXArrays/Fe7F8/src/DAT/DAT.jl:374 [inlined]",
      " [16] top-level scope",
      "    @ In[24]:1",
      " [17] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [18] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "medtair = mapslices(median, ds.layer, dims=\"Time\", max_cache=1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47214fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00007f53945f0b90"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548111a",
   "metadata": {},
   "source": [
    "# Avoiding \"slow\" data access by re-chunking\n",
    "\n",
    "When repeatedly accessing data in an un-optimal way, rechunking might be an option. For example when you plan to develop some new method and you know that it will have to access the data from the time direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9bb97aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YAXArray Dataset\n",
       "Dimensions: \n",
       "   lat                 Axis with 720 Elements from 89.875 to -89.875\n",
       "   lon                 Axis with 1440 Elements from -179.875 to 179.875\n",
       "   time                Axis with 1748 Elements from 1980-01-05T00:00:00 to 2017-12-31T00:00:00\n",
       "Variables: layer "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrechunked = setchunks(ds,(time=184,lat=90,lon=90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43423488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:56\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YAXArray Dataset\n",
       "Dimensions: \n",
       "   lat                 Axis with 720 Elements from 89.875 to -89.875\n",
       "   lon                 Axis with 1440 Elements from -179.875 to 179.875\n",
       "   time                Axis with 1748 Elements from 1980-01-05T00:00:00 to 2017-12-31T00:00:00\n",
       "Variables: layer "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedataset(dsrechunked,path = \"esdc_airtemp.zarr\", overwrite=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5dc778",
   "metadata": {},
   "source": [
    "Now we have created a new permanent copy of the dataset in zarr format and with relatively large chunks in time. This significantly speeds up computations along the time axis"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
